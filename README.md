# ğŸ§  Real-Time ASL Gesture Recognition using MediaPipe

An AI-powered assistive communication system that enables real-time American Sign Language (ASL) alphabet recognition using computer vision and machine learning. This project bridges the communication gap between deaf/mute individuals and the general public by converting hand gestures into readable text.

---

## ğŸš€ Features

* âœ‹ Real-time hand tracking using MediaPipe Hands
* ğŸ”¤ ASL alphabet recognition (Aâ€“Z)
* âš¡ Lightweight GaussianNB classifier
* ğŸ¥ Live webcam inference
* ğŸ§© Word formation from detected letters
* ğŸ›¡ï¸ Stable prediction with smoothing
* ğŸ–¥ï¸ Works on standard laptops (no special hardware)
* ğŸ”§ Windows-friendly setup

---

## ğŸ—ï¸ System Architecture

```
Webcam â†’ MediaPipe Hands â†’ Landmark Extraction â†’ GaussianNB Classifier â†’ Letter â†’ Word Builder â†’ Display
```

---

## ğŸ“‚ Project Structure

```
Gesture-Recognition/
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ gesture_clf.pkl
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ extra.py
â”‚
â”œâ”€â”€ run.py
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸ§° Tech Stack

* Python 3.10
* OpenCV
* MediaPipe
* NumPy
* Scikit-learn
* Joblib

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/Haruto1632/Gesture-Recognition.git
cd Gesture-Recognition
```

---

### 2ï¸âƒ£ Create virtual environment

```bash
py -3.10 -m venv .venv
.venv\Scripts\activate
```

---

### 3ï¸âƒ£ Install dependencies

```bash
pip install mediapipe==0.10.14 opencv-python numpy scikit-learn joblib
```

---

## â–¶ï¸ Running the Project

```bash
python run.py
```

### ğŸ® Controls

* **ESC** â†’ Exit
* **Backspace** â†’ Delete last character
* **C** â†’ Clear word (if enabled)

---

## ğŸ§ª How It Works

1. Webcam captures live video
2. MediaPipe detects hand landmarks
3. Landmarks converted to feature vector
4. GaussianNB model predicts ASL letter
5. Stable letters form words
6. Output displayed in real time

---

## ğŸ“ˆ Current Limitations

* Supports ASL alphabet only (static signs)
* Sensitive to very poor lighting
* Works best with single hand in frame
* Dynamic ASL words not yet implemented

---

## ğŸ”® Future Improvements

* ğŸ”Š Text-to-speech output
* ğŸ“± Mobile deployment
* ğŸ§  Deep learning classifier
* âœŒï¸ Two-hand support
* ğŸ—£ï¸ Dynamic ASL gesture recognition
* ğŸŒ Web-based interface

---

## ğŸ¤ Contributing

Contributions are welcome! Please open an issue or submit a pull request for improvements.

---

## ğŸ“œ License

This project is open-source and available under the MIT License.

---

## ğŸ‘¨â€ğŸ’» Author

**Haruto ã‚¢ãƒ“ã‚·ã‚§ã‚¯**

If you found this helpful, consider â­ starring the repo!
